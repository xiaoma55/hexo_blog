---
title: 玉女心经
index_img: /img/articleBg/1(93).jpg
banner_img: /img/articleBg/1(93).jpg
tags:
  - 面试
category:
  - - 编程
    - 大数据
date: 2021-03-09 10:41:25
---

`轻裘长剑，烈马狂歌。`

`忠胆义胆壮山河.`

`好一个风云来去的江湖客，好一个富贵如云你奈我何，剑光闪处如泣如歌。`

<!-- more -->

## 1 大数据

### 1.1 Zookeeper

{% post_link 大数据_ZooKeeper集群搭建 点击前往详细解释 %}。<br/><br/>

> Zookeeper 作为一个分布式的服务框架，主要用来`解决分布式集群中`应用系统的`一致性问题`。

> ZooKeeper提供的服务包括：`分布式消息同步`和`协调机制`、 `服务器节点动态上下线`、`统一配置管理`、`负载均衡`、`集群管理`等。

#### 1.1.1 Zookeeper的选举机制

##### 1.1.1.1 全新集群选举

> `选举状态`：
>> `LOOKING`，竞选状态。
> 
>> `FOLLOWING`，随从状态，同步leader状态，参与投票。
> 
>> `OBSERVING`，观察状态,同步leader状态，不参与投票。
> 
>> `LEADING`，领导者状态。
> 
>> `OBSERVING的节点不参与leader的选举`

![](/img/articleContent/面试/Zookeeper/1.png)

> 1.服务器1启动自己，给投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器1的状态一直属于Looking。
>
> 2.服务器2启动，给自己投票，同时与之前启动的服务器1交换结果，由于服务器2的编号大所以服务器2胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。
>
> 3.服务器3启动，给自己投票，同时与之前启动的服务器1,2交换信息，由于服务器3的编号最大所以服务器3胜出，此时投票数正好大于半数，所以服务器3成为领导者，服务器1,2成为小弟。
>
> 4.服务器4启动，给自己投票，同时与之前启动的服务器1,2,3交换信息，尽管服务器4的编号大，但之前服务器3已经胜出，所以服务器4只能成为小弟。
>
> 5.服务器5启动，后面的逻辑同服务器4成为小弟。

> `注意`:如果按照5,4,3,2,1的顺序启动，那么5将成为Leader，因为在满足半数条件后，ZooKeeper集群启动，5的Id最大，被选举为Leader。

##### 1.1.1.2 非全新集群选举

> 对于运行正常的zookeeper集群，中途有机器down掉，需要重新选举时，选举过程就需要加入`逻辑时钟`、`数据ID`和`服务器ID`。

> `数据ID`：数据新的version就大，数据每次更新都会更新version,在选举算法中数据越新权重越大。
> 
> `服务器ID`：就是我们配置的myid中的值，每个机器一个，比如1、2、3，编号越大在选择算法中的权重越大。
> 
> `逻辑时钟`：这个值从0开始递增,每次选举对应一个值。如果在同一次选举中,这个值是一致的。

>这样选举的标准就变成：
>> 1、逻辑时钟小的选举结果被忽略，重新投票；
>
>> 2、统一逻辑时钟后，数据id大的胜出；
>
>> 3、数据id相同的情况下，服务器id大的胜出；
>
>> 根据这个规则选出leader。

#### 1.1.2 ZooKeeper使用到的各个端口的作用

> `2888`：Follower与Leader交换信息的端口。

> `3888`：万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。

### 1.2 HDFS

{% post_link 大数据_HDFS分布式文件系统 点击前往详细解释 %}。<br/><br/>

> `shell操作地址`

https://hadoop.apache.org/docs/r2.7.5/hadoop-project-dist/hadoop-common/FileSystemShell.html#appendToFile

#### 1.2.1 HDFS读写数据流程

##### 1.2.1.1 HDFS写数据流程

![](/img/articleContent/面试/HDFS/1.png)

##### 1.2.1.2 HDFS读数据流程

![](/img/articleContent/面试/HDFS/2.png)

#### 1.2.2 HDFS NameNode原理

![](/img/articleContent/面试/HDFS/3.png)

#### 1.2.3 SecondaryNameNode

##### 1.2.3.1 SecondaryNameNode的作用

```
SecondaryNameNode的作用是合并fsimage和edits文件。
NameNode的存储目录树的信息，而目录树的信息则存放在fsimage文件中，当NameNode启动的时候会首先读取整个fsimage文件，将信息装载到内存中。
Edits文件存储日志信息，在NameNode上所有对目录的操作，增加，删除，修改等都会保存到edits文件中，并不会同步到fsimage中，当NameNode关闭的时候，也不会将fsimage和edits进行合并。
所以当NameNode启动的时候，首先装载fsimage文件，然后按照edits中的记录执行一遍所有记录的操作，最后把信息的目录树写入fsimage中，并删掉edits文件，重新启用新的edits文件。
```

##### 1.2.3.2 SecondaryNameNode出现的原因

```
但是如果NameNode执行了很多操作的话，就会导致edits文件会很大，那么在下一次启动的过程中，就会导致NameNode的启动速度很慢，慢到几个小时也不是不可能，所以出现了SecondNameNode。
```

##### 1.2.3.3 SecondaryNameNode唤醒合并的规则

```
SecondaryNameNode 会按照一定的规则被唤醒，进行fsimage和edits的合并，防止文件过大。
合并的过程是，将NameNode的fsimage和edits下载到SecondryNameNode 所在的节点的数据目录，然后合并到fsimage文件，最后上传到NameNode节点。合并的过程中不影响NameNode节点的操作
SecondaryNameNode被唤醒的条件可以在hdfs-site.xml中配置：

dfs.namenode.checkpoint.period：单位秒，默认值3600，检查点的间隔时间，当距离上次检查点执行超过该时间后启动检查点，就是edits和fsimage的合并
dfs.namenode.checkpoint.txns：事务操作次数，默认值1000000，当edits文件事务操作超过这个次数，就进行edits和fsimage的合并
dfs.namenode.checkpoint.check.period：单位秒，默认值60。1分钟检查一次操作次数
```

##### 1.2.3.4 SecondaryNameNode工作过程

```
第一步：将hdfs更新记录写入一个新的文件——edits.new。
第二步：将fsimage和editlog通过http协议发送至secondary namenode。
第三步：将fsimage与editlog合并，生成一个新的文件——fsimage.ckpt。这步之所以要在secondary namenode中进行，是因为比较耗时，如果在namenode中进行，或导致整个系统卡顿。
第四步：将生成的fsimage.ckpt通过http协议发送至namenode。
第五步：重命名fsimage.ckpt为fsimage，edits.new为edits。
第六步：等待下一次checkpoint触发SecondaryNameNode进行工作，一直这样循环操作。
```

![](/img/articleContent/面试/HDFS/4.png)

> `注意`:SecondaryNameNode 在合并 edits 和 fsimage 时需要消耗的内存和 NameNode 差不多, 所以一般
>> `SNN服务器内存一般要>=NameNode内存`
> 
>> `SNN和NameNode放在不同的机器上`

#### 1.2.4 NameNode元数据恢复

> 当NameNode发生故障时,我们可以通过将SecondaryNameNode中数据拷贝到NameNode存储数据的目录的方式来恢复NameNode的数据

> 操作步骤:

> `1 杀死NameNode进程`

```
kill -9 NameNode进程号
```

> `2 删除NameNode存储的数据`

```
rm -rf /export/server/hadoop-2.7.5/hadoopDatas/namenodeDatas/*
rm -rf /export/server/hadoop-2.7.5/hadoopDatas/nn/edits/*
```

> `3 拷贝SecondaryNameNode中数据到原NameNode存储数据目录`

```
cd /export/server/hadoop-2.7.5/hadoopDatas/namenodeDatas/
scp -r node2:/export/server/hadoop-2.7.5/hadoopDatas/snn/name/* ./
```

```
cd /export/server/hadoop-2.7.5/hadoopDatas/nn/edits
scp -r node2:/export/server/hadoop-2.7.5/hadoopDatas/dfs/snn/edits/* ./
```

> `4 重新启动NameNode`

```
hadoop-daemon.sh start namenode
```

### 1.3 MapperReduce

{% post_link 大数据_MapReduce 点击前往详细解释 %}。<br/><br/>

#### 1.3.1 MapperReduce底层运行机制

![](/img/articleContent/面试/MapperReduce/1.png)
 
### 1.4 Yarn

{% post_link 大数据_Yarn 点击前往详细解释 %}。<br/><br/>

![](/img/articleContent/面试/Yarn/1.png)

### 1.5 Hive

{% post_link 大数据_Hive 点击前往详细解释 %}。<br/><br/>

> hive 是基于 Hadoop的数据仓库的工具，依赖于hadoop

> hive 本质上来说就是SQL翻译成MR的工具,甚至更进一步可以说hive就是一个MapReduce的客户端

> hive 的数据保存在 HDFS 上

> hive 可以使用类 SQL 查询功能

> `依赖mysql，mysql存储元数据`

#### 1.5.1 内部表和外部表

##### 1.5.1.1 内部表

> 未被`external`修饰的是`内部表`（managed table）,内部表又称管理表,内部表数据存储的位置由hive.metastore.warehouse.dir参数决定（默认：/user/hive/warehouse），`删除内部表会直接删除元数据（metadata）及存储数据`，因此内部表不适合和其他工具共享数据。

##### 1.5.1.2 外部表

> 在创建表的时候可以指定external关键字创建外部表,外部表对应的文件存储在location指定的hdfs目录下,向该目录添加新文件的同时，该表也会读取到该文件(当然文件格式必须跟表定义的一致)。

> 外部表因为是指定其他的hdfs路径的数据加载到表当中来，所以hive表会认为自己不完全独占这份数据，所以`删除hive外部表的时候，数据仍然存放在hdfs当中，不会删掉`。

#### 1.5.2 分区表和分桶表

##### 1.5.2.1 分区表

> `分文件夹`。在大数据中，最常用的一种思想就是分治，我们可以把大的文件切割划分成一个个的小的文件，这样每次操作一个小的文件就会很容易了，同样的道理，在hive当中也是支持这种思想的，就是我们可以把大的数据，按照每天，或者每小时进行切分成一个个的小的文件，这样去操作小的文件就会容易得多了。

##### 1.5.2.2 分桶表

> `分文件`将数据按照指定的字段进行分成多个桶中去，说白了就是将数据按照字段进行划分，可以将数据按照字段划分到多个文件当中去。

> `Hive采用对列值哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶当中。`

##### 1.5.2.3 好处

> 指定了分区分桶后，可以大幅度提升查询效率。

```
例如我们做了分区和分桶后，按照Time分区，按照Class分组。

这样查询的时候，可以直接到Time对应的文件夹下，然后对Class字段取哈希确定是哪个分桶下，快多了。
```

##### 1.5.2.4 注意

> `分区容易造成数据倾斜`

#### 1.5.3 四个By

> 1.`ORDER BY`用于`全局排序`，就是对指定的所有排序键进行全局排序，使用ORDER BY的查询语句，最后会用一个Reduce Task来完成全局排序。

> 2.`sort by`用于分区内排序，即每个Reduce任务内排序。，则sort by只保证每个reducer的输出有序，不保证全局有序。`局部排序，但是reduce只有一个话和order by功能一样，做全局排序`

> 3.`distribute by`(字段)根据指定的字段将数据分到不同的reducer，且分发算法是hash散列。`类似MR的k2进行分区`

> 4.`cluster by`(字段) 除了具有Distribute by的功能外，还兼具sort by的排序功能。。

> 因此，如果分桶和sort字段是同一个时，此时，cluster by = distribute by + sort by。`如果distribute by字段和sort by字段等价于cluster by字段 ，只能升序排列，不能降序排列`

> `生产一般不做全局排序，都是先用sort by查出每个分区的top几个字段，再对这些字段做order by排序。`

#### 1.5.4 静态分区和动态分区

> `静态分区`

```
INSERT overwrite TABLE user PARTITION (year='2020',month='01',day='01')
SELECT 
    ...
FROM userInfo;
```

> `动态分区`

```
INSERT overwrite TABLE user PARTITION (year,month,day)
SELECT 
    ...
    user.year,
    user.month,
    user.day
FROM userInfo;
```

> `静态分区和动态分区`

```
INSERT overwrite TABLE user PARTITION (year='2020',month='01',day)
SELECT 
    ...
    user.day
FROM userInfo;
```

> `注意：hive的动态分区只能放在静态分区后面。`
>> 因为hive解析SQL的时候，是先去创建静态分区文件夹，再解析SQL，再根据解析的结果去创建动态文件夹，再去插入。<br/>
> 
>> 之所以产生这个，因该是hive的设计缺陷，如果改成先解析SQL，再去创建文件夹的话，那么动态分区和静态分区混用的时候，顺序就没关系了。 

### 1.6 Redis

{% post_link 大数据_Redis 点击前往详细解释 %}。<br/><br/>

#### 1.6.1 缓存穿透

> `缓存穿透`：key对应的数据在`数据源并不存在`，每次针对此key的请求从`缓存获取不到`，请求都会到数据源，从而可能压垮数据源。

> `一言以蔽之：查询Key，缓存和数据源都没有，频繁查询数据源`

> 比如用一个不存在的用户id获取用户信息，无论论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。

> `如何解决缓存穿透`：当查询不存在时，也将结果保存在缓存中。[PS：布隆过滤器虽快，但不能准确判断key值是否已存在，不推荐]

#### 1.6.2 缓存击穿

> `缓存击穿`：key对应的`数据库存在`，但在`redis中过期`，此时若有`大量并发请求`过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。

> `一言以蔽之：查询Key，缓存过期，大量并发，频繁查询数据源`

> 业界比较常用的做法：`使用互斥锁`。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db（查询数据库），而是先使用Redis的SETNX操作去set一个mutex key【此key作为互斥锁，在指定的 key 不存在时，为key设置指定的值，返回1；`key存在时返回0`】，只让一个线程构建缓存，其他线程等待构建缓存的线程执行完，重新从缓存获取数据。

```
String get(String key) {  
   String value = redis.get(key);  
   if (value  == null) {  
// 如果key不存在，则设置为1
    if (redis.setnx(key_mutex, "1")) {  
        // 设置key的过期时间为3分钟  
        redis.expire(key_mutex, 3 * 60)  
// 从db中加载数据，但注意：只有一个线程能进入到这里，其他线程访问的时候已有课key_mutex
        value = db.get(key);  
// 从数据库中加载成功，则设置对应的数据
        redis.set(key, value);  
        redis.delete(key_mutex);  
    } else {  
        //其他线程休息50毫秒后重试  
        Thread.sleep(50);  
        get(key);  
    }  
  }  
}
```

#### 1.6.3 缓存雪崩

> `缓存雪崩`：当`缓存服务器重启`或者大量缓存集中在`某一个时间段失`效，这样在失效的时候，也会给后端系统(比如DB)带来很大压力。

`一言以蔽之：缓存不可用（服务器重启或缓存失效），频繁查询数据源`

> `与缓存击穿的区别`在于这里针对很多key缓存，前者则是某一个key。

> 缓存正常从Redis中获取，示意图如下：

![](/img/articleContent/面试/Redis/1.png)

> 缓存失效瞬间示意图如下：

![](/img/articleContent/面试/Redis/2.png)

> 缓存失效时的雪崩效应对底层系统的冲击非常可怕！

> 大多数系统设计者考虑用`加锁或者队列`的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。

> 还有一个简单方案就时`将缓存失效时间分散开`，比如可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。

#### 1.6.4 过期策略

> 当`Redis中缓存的key过期`了，`Redis什么时间清理`。

> `定时过期`
>> 每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。

> `惰性过期`
>> 只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。

> `定期过期`
>> 每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。

#### 1.6.5 内存淘汰策略

> `在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据`

> 实际项目中设置内存淘汰策略：maxmemory-policy `allkeys-lru`，移除最近最少使用的key。

```
# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory
# is reached. You can select among five behaviors:
#最大内存策略：当到达最大使用内存时，你可以在下面5种行为中选择，Redis如何选择淘汰数据库键
#当内存不足以容纳新写入数据时

# volatile-lru -> remove the key with an expire set using an LRU algorithm
# volatile-lru ：在设置了过期时间的键空间中，移除最近最少使用的key。这种情况一般是把 redis 既当缓存，又做持久化存储的时候才用。

# allkeys-lru -> remove any key according to the LRU algorithm
# allkeys-lru ： 移除最近最少使用的key （推荐）

# volatile-random -> remove a random key with an expire set
# volatile-random ： 在设置了过期时间的键空间中，随机移除一个键，不推荐

# allkeys-random -> remove a random key, any key
# allkeys-random ： 直接在键空间中随机移除一个键，弄啥叻

# volatile-ttl -> remove the key with the nearest expire time (minor TTL)
# volatile-ttl ： 在设置了过期时间的键空间中，有更早过期时间的key优先移除 不推荐

# noeviction -> don't expire at all, just return an error on write operations
# noeviction ： 不做过键处理，只返回一个写操作错误。 不推荐

# Note: with any of the above policies, Redis will return an error on write
#       operations, when there are no suitable keys for eviction.
# 上面所有的策略下，在没有合适的淘汰删除的键时，执行写操作时，Redis 会返回一个错误。下面是写入命令：
#       At the date of writing these commands are: set setnx setex append
#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd
#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby
#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby
#       getset mset msetnx exec sort

# 内存淘汰策略默认是：
# The default is:
# maxmemory-policy noeviction
```

#### 1.6.6 Redis的持久化

##### 1.6.6.1 RDB持久化方案

```
cd /export/server/redis-3.2.8/
vim redis.conf
# 第202行
save 900 1
save 300 10
save 60 10000
save 5 1

save 60 10000 表示在60秒内，有10000个key发生变化，就会生成一份redis的快照
```

##### 1.6.6.2 AOF持久化方案

> 采用AOF持久方式时，Redis会把每一个写请求都记录在一个日志文件里。在Redis重启时，会把AOF文件中记录的所有写操作顺序执行一遍，确保数据恢复到最新。

> AOF默认是关闭的，如要开启，进行如下配置：

```
# 第594行
appendonly yes
```

> AOF提供了三种fsync配置：`always/everysec/no`，通过配置项`[appendfsync]`指定：

```
appendfsync no：不进行fsync，将flush文件的时机交给OS决定，速度最快
appendfsync always：每写入一条日志就进行一次fsync操作，数据安全性最高，但速度最慢
appendfsync everysec：折中的做法，交由后台线程每秒fsync一次

AOF + fsync always的设置虽然能够绝对确保数据安全，但每个操作都会触发一次fsync，会对Redis的性能有比较明显的影响
AOF + fsync every second是比较好的折中方案，每秒fsync一次
AOF + fsync never会提供AOF持久化方案下的最优性能
使用RDB持久化通常会提供比使用AOF更高的性能，但需要注意RDB的策略配置
```


#### 1.6.7 Redis的命名规范

> 使用统一的命名规范

> 一般使用业务名(或数据库名)为前缀，`用冒号分隔`，例如，`业务名:表名:id`。
>> 例如：`shop:usr:msg_code`（电商:用户:验证码）
> 

> `控制key名称的长度，不要使用过长的key`
>> 在保证语义清晰的情况下，尽量减少Key的长度。有些常用单词可使用缩写，例如，user缩写为u，messages缩写为msg。

> `名称中不要包含特殊字符`
>> 包含空格、单双引号以及其他转义字符

#### 1.6.8 集群

> 问题一：`Redis的多数据库机制，了解多少`

![](/img/articleContent/面试/Redis/3.png)

> 问题二：`懂Redis的批量操作么？`

![](/img/articleContent/面试/Redis/4.png)

> 问题三：`Redis集群机制中，你觉得有什么不足的地方吗？`

![](/img/articleContent/面试/Redis/5.png)

> 问题四：`在Redis集群模式下，如何进行批量操作？`

![](/img/articleContent/面试/Redis/6.png)

> 问题五：`懂Redis事务么？`

![](/img/articleContent/面试/Redis/7.png)

### 1.7

### 1.8

### 1.9


## 联系博主，加入【羊山丨交流社区】
![联系博主](/img/icon/wechatFindMe.png)

![](/img/articleContent/面试/目录/1.png)

{% post_link 大数据_Redis 点击前往详细解释 %}。<br/><br/>